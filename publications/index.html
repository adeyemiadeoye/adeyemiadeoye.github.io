<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="dBRgkx3q9AgNWKiuV37d2e-Iw5c8_vACqSWsuoUeBNc"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Publications | Adeyemi Damilare Adeoye</title> <meta name="author" content="Adeyemi Damilare Adeoye"> <meta name="description" content="Website of Adeyemi Damilare Adeoye. "> <meta name="keywords" content="recurrent-neural-networks, optimization, mathematics, machine-learning, data-driven-control, academic-website"> <meta name="viewport" content="width=1024"> <link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin> <link rel="preload" as="image" href="/assets/img/bg-side-3-freepik.jpg"> <link rel="preload" as="image" href="/assets/img/home-image.png"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Space+Grotesk:300,400,500,700|IBM+Plex+Sans:300,400,500,700|IBM+Plex+Mono:300,400,500,700|Merriweather+Sans:300,400,500,700|Nunito:300,400,500,700|Poppins:300,400,500,700|Ubuntu:300,400,500,700|Consolas:300,400,500,700|B612:300,400,500,700|Lato:300,400,500,700|Roboto:300,400,500,700|Fira+Code:300,400,500,700|PT+Sans:300,400,500,700|Gentium+Book+Plus:300,400,500,700|Source+Sans+Pro:300,400,500,700|Josefin+Sans:300,400,500,700|Hanken+Grotesk:100,300,400,500,700|Maven+Pro:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/fonts/juliamono.css" type="text/css"> <link rel="stylesheet" href="/assets/css/fonts/juliamono-regular.css" type="text/css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.css" integrity="sha384-zh0CIslj+VczCZtlzBcjt5ppRcsAmDnRem7ESsYwWwg3m/OaJ2l4x7YBZl9Kxxib" crossorigin="anonymous"> <script>function renderKatex(){let e={};if(customElements){class t extends HTMLElement{constructor(){super(),katex.render(this.innerText,this,{throwOnError:!1,displayMode:!1,macros:e,output:"html"})}}customElements.define("katex-inline",t);class r extends HTMLElement{constructor(){super(),katex.render(this.innerText,this,{throwOnError:!1,displayMode:!0,macros:e,output:"html"})}}customElements.define("katex-block",r)}else document.querySelectorAll("katex-inline").forEach(t=>{katex.render(t.innerText,t,{throwOnError:!1,displayMode:!1,macros:e,output:"html"})}),document.querySelectorAll("katex-block").forEach(t=>{katex.render(t.innerText,t,{throwOnError:!1,displayMode:!0,macros:e,output:"html"})})}</script> <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.js" integrity="sha384-Rma6DA2IPUwhNxmrB/7S3Tno0YY7sFu9WSYMCuulLhIqYSGZ2gKCJWIqhBWqMQfh" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://adeyemiadeoye.github.io/publications/"> </head> <body class="fixed-top-nav sticky-bottom-footer"> <div class="container mt-5"> <div class="container" style="max-width: 100%; margin-left: auto; margin-right: auto;"> <div class="row"> <aside class="col-md-3 d-none d-md-block"> <aside class="site-sidebar" style="padding-right:0; padding-left:0;"> <div class="sidebar d-flex flex-column" style="align-items: flex-start; background-image: url('/assets/img/bg-side-3-freepik.jpg'); background-size: cover; background-position: center; background-repeat: repeat; overflow-x:hidden; padding: .75rem; min-height:100vh; box-sizing: border-box; width:100%;"> <div class="sidebar-header text-center mb-3" style="width:100%;"> <img src="/assets/img/home-image.png" alt="Navigation" class="img-fluid" style="max-height:70px; display:inline-block;" loading="eager" fetchpriority="high"> <h4 class="mt-2 mb-1" style="color:white; font-family:'Trebuchet MS', 'Lucida Sans Unicode', 'Lucida Grande', 'Lucida Sans', Arial, sans-serif;">Adeyemi D. Adeoye</h4> </div> <ul class="list-unstyled w-100" style="padding:0;"> <li class="mb-3 text-center" style="width:100%;"><a href="/" style="width:100%;">Home</a></li> <li class="mb-3 text-center" style="width:100%;"><a href="/publications/" style="width:100%;">Publications</a></li> <li class="mb-3 text-center" style="width:100%;"><a href="/talks/" style="width:100%;">Talks</a></li> <li class="mb-3 text-center" style="width:100%;"><a href="/software/" style="width:100%;">Software</a></li> <li class="mb-3 text-center" style="width:100%;"><a href="/cv/" style="width:100%;">Short CV</a></li> </ul> <hr style="border-top:1px solid rgba(0,0,0,0.3); width:100%;"> <div class="mb-3 social" style="width:100%; text-align:center; font-size: 20px;"> <div class="contact-icons"> <a href="https://scholar.google.com/citations?user=G8fKpqwAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://orcid.org/0000-0001-7048-0984" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://www.webofscience.com/wos/author/record/DWH-9882-2022" title="Web of Science" rel="external nofollow noopener" target="_blank"><i class="ai ai-clarivate"></i></a> <a href="https://www.scopus.com/authid/detail.uri?authorId=57383593600" title="Scopus" rel="external nofollow noopener" target="_blank"><i class="ai ai-scopus"></i></a> <a href="https://www.researchgate.net/profile/Adeyemi-Adeoye/" title="ResearchGate" rel="external nofollow noopener" target="_blank"><i class="ai ai-researchgate"></i></a> <a href="https://github.com/adeyemiadeoye" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/adeyemi-adeoye" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a> <a href="https://www.semanticscholar.org/author/2145264837" title="Semantic Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-semantic-scholar"></i></a> </div> </div> <hr style="border-top:1px solid rgba(0,0,0,0.3); width:100%;"> <div class="sidebar-footer text-center small" style="width:100%; color: var(--global-text-color);"> <p style="margin-bottom:0.25rem;">© 2025 Adeyemi D. Adeoye.</p> <p style="margin-bottom:0.25rem; font-size: x-small;">Powered by <a href="https://jekyllrb.com/" target="_blank" style="color: var(--global-text-color);" rel="external nofollow noopener">Jekyll</a>. </p> </div> </div> </aside> </aside> <main class="col-md-10 content-with-sidebar"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description"></p> </header> <article class="post-content"> <div id="markdown-content"> <div style="font-size: small; margin-top: -1rem;">See also: <span class="links" style="text-transform: lowercase; font-size: x-small;"> <a href="https://scholar.google.com/citations?user=G8fKpqwAAAAJ" target="_blank" class="ai ai-google-scholar" role="button" rel="external nofollow noopener">Google Scholar Profile</a> </span> </div> <div class="publications"> <h5>Preprints</h5> <ol class="bibliography"> <li> <div class="row"> <div id="adeoye2025proximalaugmentedlagrangianmethod" class="col"> <span id="adeoye2025proximalaugmentedlagrangianmethod"><span style="font-weight: 500">A. D. Adeoye, P. Latafat and A. Bemporad</span>. (<span style="font-weight: 500">2025</span>). <span style="font-weight: 500">“A proximal augmented Lagrangian method for nonconvex optimization with equality and inequality constraints.”</span> <i>arXiv preprint arXiv:2509.02894</i>.</span> <span class="links" style="text-transform: lowercase;"> <a href="https://arxiv.org/abs/2509.02894" class="fas fa-link" role="button" rel="external nofollow noopener" target="_blank">LINK</a> <a href="https://arxiv.org/pdf/2509.02894" class="fas fa-file-pdf" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/adeyemiadeoye/p-balm" class="fas fa-code" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a class="abstract fas fa-align-left" role="button">Abs</a> <a class="bibtex fas fa-quote-right" role="button">Bib</a> </span> <div class="abstract hidden"> <p>We propose an inexact proximal augmented Lagrangian method (P-ALM) for solving nonconvex structured optimization problems. The proposed method features an easily implementable rule not only for updating the penalty parameters, but also for adaptively tuning the proximal term. It allows the penalty parameter to grow rapidly in the early stages to speed up progress, while ameliorating the issue of ill-conditioning in later iterations, a well-known drawback of the traditional approach of linearly increasing the penalty parameters. A key element in our analysis lies in the observation that the augmented Lagrangian can be controlled effectively along the iterates, provided an initial feasible point is available. Our analysis, while simple, provides a new theoretical perspective about P-ALM and, as a by-product, results in similar convergence properties for its non-proximal variant, the classical augmented Lagrangian method (ALM). Numerical experiments, including convex and nonconvex problem instances, demonstrate the effectiveness of our approach.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">adeoye2025proximalaugmentedlagrangianmethod</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{A proximal augmented Lagrangian method for nonconvex optimization with equality and inequality constraints}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Adeoye, Adeyemi D. and Latafat, Puya and Bemporad, Alberto}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2509.02894}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{math.OC}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2509.02894}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> <script>document.addEventListener("DOMContentLoaded",function(){const e=document.querySelectorAll(".publications ol > li");if(console.log(`Total list items found: ${e.length}`),0===e.length)return void console.error("No list items found within '.publications ol > li'. Ensure that the bibliography tags generate <ol> and <li> elements.");const n=e.length;e.forEach((e,t)=>{const o=n-t;if(console.log(`Assigning number ${o} to list item at index ${t}`),e.querySelector(".reverse-number"))return void console.warn(`List item at index ${t} already has a reverse number. Skipping.`);const l=document.createElement("span");l.classList.add("reverse-number"),l.innerHTML="&bull;",l.style.fontSize="small",e.prepend(l)})});</script> </li> <li> <div class="row"> <div id="adeoye2023self" class="col"> <span id="adeoye2023self"><span style="font-weight: 500">A. D. Adeoye and A. Bemporad</span>. (<span style="font-weight: 500">2023</span>). <span style="font-weight: 500">“Self-concordant Smoothing for Large-Scale Convex Composite Optimization.”</span> <i>arXiv preprint arXiv:2309.01781</i>.</span> <span class="links" style="text-transform: lowercase;"> <a href="https://arxiv.org/abs/2309.01781" class="fas fa-link" role="button" rel="external nofollow noopener" target="_blank">LINK</a> <a href="https://arxiv.org/pdf/2309.01781.pdf" class="fas fa-file-pdf" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/adeyemiadeoye/SelfConcordantSmoothOptimization.jl" class="fas fa-code" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a class="abstract fas fa-align-left" role="button">Abs</a> <a class="bibtex fas fa-quote-right" role="button">Bib</a> </span> <div class="abstract hidden"> <p>We introduce a notion of self-concordant smoothing for minimizing the sum of two convex functions, one of which is smooth and the other may be nonsmooth. The key highlight of our approach is in a natural property of the resulting problem’s structure which provides us with a variable-metric selection method and a step-length selection rule particularly suitable for proximal Newton-type algorithms. In addition, we efficiently handle specific structures promoted by the nonsmooth function, such as l1-regularization and group-lasso penalties. We prove the convergence of two resulting algorithms: Prox-N-SCORE, a proximal Newton algorithm and Prox-GGN-SCORE, a proximal generalized Gauss-Newton algorithm. The Prox-GGN-SCORE algorithm highlights an important approximation procedure which helps to significantly reduce most of the computational overhead associated with the inverse Hessian. This approximation is essentially useful for overparameterized machine learning models and in the mini-batch settings. Numerical examples on both synthetic and real datasets demonstrate the efficiency of our approach and its superiority over existing approaches. A Julia package implementing the proposed algorithms is available at https://github.com/adeyemiadeoye/SelfConcordantSmoothOptimization.jl.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">adeoye2023self</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Self-concordant Smoothing for Large-Scale Convex Composite Optimization}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Adeoye, Adeyemi D and Bemporad, Alberto}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2309.01781}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2309.01781}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{math.OC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> <script>document.addEventListener("DOMContentLoaded",function(){const e=document.querySelectorAll(".publications ol > li");if(console.log(`Total list items found: ${e.length}`),0===e.length)return void console.error("No list items found within '.publications ol > li'. Ensure that the bibliography tags generate <ol> and <li> elements.");const n=e.length;e.forEach((e,t)=>{const o=n-t;if(console.log(`Assigning number ${o} to list item at index ${t}`),e.querySelector(".reverse-number"))return void console.warn(`List item at index ${t} already has a reverse number. Skipping.`);const l=document.createElement("span");l.classList.add("reverse-number"),l.innerHTML="&bull;",l.style.fontSize="small",e.prepend(l)})});</script> </li> </ol> <h5>Journal articles</h5> <ol class="bibliography"> <li> <div class="row"> <div id="KORBIT2025131738" class="col"> <span id="KORBIT2025131738"><span style="font-weight: 500">M. Korbit, A. D. Adeoye, A. Bemporad and M. Zanon</span>. (<span style="font-weight: 500">2025</span>). <span style="font-weight: 500">“Exact Gauss-Newton optimization for training deep neural networks.”</span> <i>Neurocomputing</i> <span style="font-weight: normal">658</span>: 131738.</span> <span class="links" style="text-transform: lowercase;"> <a href="https://www.sciencedirect.com/science/article/pii/S0925231225024105" class="fas fa-link" role="button" rel="external nofollow noopener" target="_blank">LINK</a> <a class="abstract fas fa-align-left" role="button">Abs</a> <a class="bibtex fas fa-quote-right" role="button">Bib</a> </span> <div class="abstract hidden"> <p>We present Exact Gauss-Newton (EGN), a stochastic second-order optimization algorithm that combines the generalized Gauss-Newton (GN) Hessian approximation with low-rank linear algebra to compute the descent direction. Leveraging the Duncan-Guttman matrix identity, the parameter update is obtained by factorizing a matrix which has the size of the mini-batch. This is particularly advantageous for large-scale machine learning problems where the dimension of the neural network parameter vector is several orders of magnitude larger than the batch size. Additionally, we show how improvements such as line search, adaptive regularization, and momentum can be seamlessly added to EGN to further accelerate the algorithm. Moreover, under mild assumptions, we prove that our algorithm converges in expectation to a stationary point of the objective. Finally, our numerical experiments demonstrate that EGN consistently exceeds, or at most matches the generalization performance of well-tuned SGD, Adam, GAF, SQN, and SGN optimizers across various supervised and reinforcement learning tasks.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">KORBIT2025131738</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Exact Gauss-Newton optimization for training deep neural networks}}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Neurocomputing}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{658}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{131738}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0925-2312}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.neucom.2025.131738}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Korbit, Mikalai and Adeoye, Adeyemi D. and Bemporad, Alberto and Zanon, Mario}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Stochastic optimization, Second-order optimization, Gauss-newton hessian approximation, Machine learning, Reinforcement learning}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> <script>document.addEventListener("DOMContentLoaded",function(){const e=document.querySelectorAll(".publications ol > li");if(console.log(`Total list items found: ${e.length}`),0===e.length)return void console.error("No list items found within '.publications ol > li'. Ensure that the bibliography tags generate <ol> and <li> elements.");const n=e.length;e.forEach((e,t)=>{const o=n-t;if(console.log(`Assigning number ${o} to list item at index ${t}`),e.querySelector(".reverse-number"))return void console.warn(`List item at index ${t} already has a reverse number. Skipping.`);const l=document.createElement("span");l.classList.add("reverse-number"),l.innerHTML="&bull;",l.style.fontSize="small",e.prepend(l)})});</script> </li> <li> <div class="row"> <div id="adeoye2025isqprnn" class="col"> <span id="adeoye2025isqprnn"><span style="font-weight: 500">A. D. Adeoye and A. Bemporad</span>. (<span style="font-weight: 500">2025</span>). <span style="font-weight: 500">“An Inexact Sequential Quadratic Programming Method for Learning and Control of Recurrent Neural Networks.”</span> <i>IEEE Transactions on Neural Networks and Learning Systems</i> <span style="font-weight: normal">36</span>: 2762–2776.</span> <span class="links" style="text-transform: lowercase;"> <a href="https://ieeexplore.ieee.org/document/10418043" class="fas fa-link" role="button" rel="external nofollow noopener" target="_blank">LINK</a> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=10418043" class="fas fa-file-pdf" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a class="abstract fas fa-align-left" role="button">Abs</a> <a class="bibtex fas fa-quote-right" role="button">Bib</a> </span> <div class="abstract hidden"> <p>This article considers the two-stage approach to solving a partially observable Markov decision process (POMDP): the identification stage and the (optimal) control stage. We present an inexact sequential quadratic programming framework for recurrent neural network learning (iSQPRL) for solving the identification stage of the POMDP, in which the true system is approximated by a recurrent neural network (RNN) with dynamically consistent overshooting (DCRNN). We formulate the learning problem as a constrained optimization problem and study the quadratic programming (QP) subproblem with a convergence analysis under a restarted Krylov-subspace iterative scheme that implicitly exploits the structure of the associated Karush–Kuhn–Tucker (KKT) subsystem. In the control stage, where a feedforward neural network (FNN) controller is designed on top of the RNN model, we adapt a generalized Gauss–Newton (GGN) algorithm that exploits useful approximations to the curvature terms of the training data and selects its mini-batch step size using a known property of some regularization function. Simulation results are provided to demonstrate the effectiveness of our approach.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">adeoye2025isqprnn</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Adeoye, Adeyemi D. and Bemporad, Alberto}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Neural Networks and Learning Systems}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{An Inexact Sequential Quadratic Programming Method for Learning and Control of Recurrent Neural Networks}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{36}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2762-2776}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Training;Recurrent neural networks;Optimization;Neural networks;Quadratic programming;Process control;Prediction algorithms;Gauss–Newton methods;markov decision processes;numerical optimization;recurrent neural networks (RNNs);reinforcement learning (RL);sequential quadratic programming (SQP)}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TNNLS.2024.3354855}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> <script>document.addEventListener("DOMContentLoaded",function(){const e=document.querySelectorAll(".publications ol > li");if(console.log(`Total list items found: ${e.length}`),0===e.length)return void console.error("No list items found within '.publications ol > li'. Ensure that the bibliography tags generate <ol> and <li> elements.");const n=e.length;e.forEach((e,t)=>{const o=n-t;if(console.log(`Assigning number ${o} to list item at index ${t}`),e.querySelector(".reverse-number"))return void console.warn(`List item at index ${t} already has a reverse number. Skipping.`);const l=document.createElement("span");l.classList.add("reverse-number"),l.innerHTML="&bull;",l.style.fontSize="small",e.prepend(l)})});</script> </li> <li> <div class="row"> <div id="adeoye2023score" class="col"> <span id="adeoye2023score"><span style="font-weight: 500">A. D. Adeoye and A. Bemporad</span>. (<span style="font-weight: 500">2023</span>). <span style="font-weight: 500">“SCORE: approximating curvature information under self-concordant regularization.”</span> <i>Computational Optimization and Applications</i> <span style="font-weight: normal">86</span>: 599–626. Springer.</span> <span class="links" style="text-transform: lowercase;"> <a href="https://link.springer.com/article/10.1007/s10589-023-00502-2" class="fas fa-link" role="button" rel="external nofollow noopener" target="_blank">LINK</a> <a href="https://rdcu.be/dgooa" class="fas fa-file-pdf" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a class="abstract fas fa-align-left" role="button">Abs</a> <a class="bibtex fas fa-quote-right" role="button">Bib</a> </span> <div class="abstract hidden"> <p>Optimization problems that include regularization functions in their objectives are regularly solved in many applications. When one seeks second-order methods for such problems, it may be desirable to exploit specific properties of some of these regularization functions when accounting for curvature information in the solution steps to speed up convergence. In this paper, we propose the SCORE (self-concordant regularization) framework for unconstrained minimization problems which incorporates second-order information in the Newton-decrement framework for convex optimization. We propose the generalized Gauss–Newton with Self-Concordant Regularization (GGN-SCORE) algorithm that updates the minimization variables each time it receives a new input batch. The proposed algorithm exploits the structure of the second-order information in the Hessian matrix, thereby reducing computational overhead. GGN-SCORE demonstrates how to speed up convergence while also improving model generalization for problems that involve regularized minimization under the proposed SCORE framework. Numerical experiments show the efficiency of our method and its fast convergence, which compare favorably against baseline first-order and quasi-Newton methods. Additional experiments involving non-convex (overparameterized) neural network training problems show that the proposed method is promising for non-convex optimization.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">adeoye2023score</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{SCORE: approximating curvature information under self-concordant regularization}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Adeoye, Adeyemi D and Bemporad, Alberto}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computational Optimization and Applications}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0926-6003}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s10589-023-00502-2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{599--626}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{86}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> <script>document.addEventListener("DOMContentLoaded",function(){const e=document.querySelectorAll(".publications ol > li");if(console.log(`Total list items found: ${e.length}`),0===e.length)return void console.error("No list items found within '.publications ol > li'. Ensure that the bibliography tags generate <ol> and <li> elements.");const n=e.length;e.forEach((e,t)=>{const o=n-t;if(console.log(`Assigning number ${o} to list item at index ${t}`),e.querySelector(".reverse-number"))return void console.warn(`List item at index ${t} already has a reverse number. Skipping.`);const l=document.createElement("span");l.classList.add("reverse-number"),l.innerHTML="&bull;",l.style.fontSize="small",e.prepend(l)})});</script> </li> <li> <div class="row"> <div id="abubakar2020effects" class="col"> <span id="abubakar2020effects"><span style="font-weight: 500">J. U. Abubakar and A. D. Adeoye</span>. (<span style="font-weight: 500">2020</span>). <span style="font-weight: 500">“Effects of radiative heat and magnetic field on blood flow in an inclined tapered stenosed porous artery.”</span> <i>Journal of Taibah University for Science</i> <span style="font-weight: normal">14</span>: 77–86. Taylor &amp; Francis.</span> <span class="links" style="text-transform: lowercase;"> <a href="https://www.tandfonline.com/doi/full/10.1080/16583655.2019.1701397" class="fas fa-link" role="button" rel="external nofollow noopener" target="_blank">LINK</a> <a href="https://www.tandfonline.com/doi/epdf/10.1080/16583655.2019.1701397" class="fas fa-file-pdf" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a class="abstract fas fa-align-left" role="button">Abs</a> <a class="bibtex fas fa-quote-right" role="button">Bib</a> </span> <div class="abstract hidden"> <p>A porous tapered inclined stenosed artery under the influence of magnetic field with radiation was considered. The momentum and energy equations with thin radiation governing the blood flow in the inclined artery were obtained taking the flow to be Newtonian. These equations were simplified under assumptions of mild stenosis, non-dimensionalized and solved using Differential Transform Method (DTM). The DTM were coded on Mathematica software to obtain expressions for velocity, temperature and the volumetric flow rate of the blood. The results presented graphically show that the velocity of the blood flow and the blood temperature decreases as the radiation parameter (N) increases.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">abubakar2020effects</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Abubakar, J. U. and Adeoye, A. D.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Effects of radiative heat and magnetic field on blood flow in an inclined tapered stenosed porous artery}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Taibah University for Science}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{14}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{77-86}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Taylor &amp; Francis}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1080/16583655.2019.1701397}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> <script>document.addEventListener("DOMContentLoaded",function(){const e=document.querySelectorAll(".publications ol > li");if(console.log(`Total list items found: ${e.length}`),0===e.length)return void console.error("No list items found within '.publications ol > li'. Ensure that the bibliography tags generate <ol> and <li> elements.");const n=e.length;e.forEach((e,t)=>{const o=n-t;if(console.log(`Assigning number ${o} to list item at index ${t}`),e.querySelector(".reverse-number"))return void console.warn(`List item at index ${t} already has a reverse number. Skipping.`);const l=document.createElement("span");l.classList.add("reverse-number"),l.innerHTML="&bull;",l.style.fontSize="small",e.prepend(l)})});</script> </li> </ol> <h5>Theses &amp; technical reports</h5> <ol class="bibliography"> <li> <div class="row"> <div id="adeoyephdthesis2025" class="col"> <span id="adeoyephdthesis2025"><span style="font-weight: 500">A. D. Adeoye</span>. (<span style="font-weight: 500">2025</span>). <span style="font-weight: 500">“Quasi-Newton methods for solving nonsmooth optimization problems in learning and control.”</span> IMT School for Advanced Studies Lucca, Italy.</span> <span class="links" style="text-transform: lowercase;"> <a href="http://e-theses.imtlucca.it/449/" class="fas fa-link" role="button" rel="external nofollow noopener" target="_blank">LINK</a> <a href="http://e-theses.imtlucca.it/449/1/Adeoye_phdthesis.pdf" class="fas fa-file-pdf" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="/assets/pdf/Adeyemi_thesis_slides.pdf" class="fas fa-file-pdf" role="button">Slides</a> <a class="abstract fas fa-align-left" role="button">Abs</a> <a class="bibtex fas fa-quote-right" role="button">Bib</a> </span> <div class="abstract hidden"> <p>This thesis is concerned with the design and analysis of some quasi-Newton methods for solving optimization problems in machine learning and control of nonlinear dynamical systems. The proposed algorithms are designed to exploit approximate second-order information to improve convergence rates, stability, and generalization of the learned models and control policies. The thesis is organized into two main parts. In the first part, we present a generalized Gauss-Newton algorithm that uses an adaptive step-size selection strategy and preserves the affine-invariant property of Newton’s method. This algorithm significantly reduces the computational cost of Gauss-Newton methods, particularly in mini-batch supervised learning. We then extend this with a proximal method for nonsmooth convex composite optimization, resulting in two new algorithms. In the second part, we treat learning and control problems in the training of neural networks. First, we present a rigorous theoretical study of the generalized Gauss-Newton algorithm for the optimization of feedforward neural networks. This study establishes a non-asymptotic guarantee for the convergence of feedforward neural networks with a general explicit regularizer. Then, an inexact sequential quadratic programming framework is proposed for optimal control in recurrent neural networks, using a two-stage approach for system identification and optimal control policy selection. Several practical applications of all the proposed algorithms are demonstrated through numerical experiments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@phdthesis</span><span class="p">{</span><span class="nl">adeoyephdthesis2025</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Quasi-Newton methods for solving nonsmooth optimization problems in learning and control}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Adeoye, Adeyemi Damilare}</span><span class="p">,</span>
  <span class="na">school</span> <span class="p">=</span> <span class="s">{IMT School for Advanced Studies Lucca, Italy}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.13118/imtlucca/e-theses/449}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> <script>document.addEventListener("DOMContentLoaded",function(){const e=document.querySelectorAll(".publications ol > li");if(console.log(`Total list items found: ${e.length}`),0===e.length)return void console.error("No list items found within '.publications ol > li'. Ensure that the bibliography tags generate <ol> and <li> elements.");const n=e.length;e.forEach((e,t)=>{const o=n-t;if(console.log(`Assigning number ${o} to list item at index ${t}`),e.querySelector(".reverse-number"))return void console.warn(`List item at index ${t} already has a reverse number. Skipping.`);const l=document.createElement("span");l.classList.add("reverse-number"),l.innerHTML="&bull;",l.style.fontSize="small",e.prepend(l)})});</script> </li> <li> <div class="row"> <div id="adeoye2024regularized" class="col"> <span id="adeoye2024regularized"><span style="font-weight: 500">A. D. Adeoye, P. C. Petersen and A. Bemporad</span>. (<span style="font-weight: 500">2024</span>). <span style="font-weight: 500">“Regularized Gauss-Newton for Optimizing Overparameterized Neural Networks.”</span> <i>arXiv preprint arXiv:2404.14875</i>.</span> <span class="links" style="text-transform: lowercase;"> <a href="https://arxiv.org/abs/2404.14875" class="fas fa-link" role="button" rel="external nofollow noopener" target="_blank">LINK</a> <a href="https://arxiv.org/pdf/2404.14875" class="fas fa-file-pdf" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/adeyemiadeoye/ggn-score-nn" class="fas fa-code" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a class="abstract fas fa-align-left" role="button">Abs</a> <a class="bibtex fas fa-quote-right" role="button">Bib</a> </span> <div class="abstract hidden"> <p>The generalized Gauss-Newton (GGN) optimization method incorporates curvature estimates into its solution steps, and provides a good approximation to the Newton method for large-scale optimization problems. GGN has been found particularly interesting for practical training of deep neural networks, not only for its impressive convergence speed, but also for its close relation with neural tangent kernel regression, which is central to recent studies that aim to understand the optimization and generalization properties of neural networks. This work studies a GGN method for optimizing a two-layer neural network with explicit regularization. In particular, we consider a class of generalized self-concordant (GSC) functions that provide smooth approximations to commonly-used penalty terms in the objective function of the optimization problem. This approach provides an adaptive learning rate selection technique that requires little to no tuning for optimal performance. We study the convergence of the two-layer neural network, considered to be overparameterized, in the optimization loop of the resulting GGN method for a given scaling of the network parameters. Our numerical experiments highlight specific aspects of GSC regularization that help to improve generalization of the optimized neural network. The code to reproduce the experimental results is available at https://github.com/adeyemiadeoye/ggn-score-nn.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">adeoye2024regularized</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Regularized Gauss-Newton for Optimizing Overparameterized Neural Networks}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Adeoye, Adeyemi D and Petersen, Philipp Christian and Bemporad, Alberto}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2404.14875}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2404.14875}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.LG}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> <script>document.addEventListener("DOMContentLoaded",function(){const e=document.querySelectorAll(".publications ol > li");if(console.log(`Total list items found: ${e.length}`),0===e.length)return void console.error("No list items found within '.publications ol > li'. Ensure that the bibliography tags generate <ol> and <li> elements.");const n=e.length;e.forEach((e,t)=>{const o=n-t;if(console.log(`Assigning number ${o} to list item at index ${t}`),e.querySelector(".reverse-number"))return void console.warn(`List item at index ${t} already has a reverse number. Skipping.`);const l=document.createElement("span");l.classList.add("reverse-number"),l.innerHTML="&bull;",l.style.fontSize="small",e.prepend(l)})});</script> </li> <li> <div class="row"> <div id="adeoye2021sc" class="col"> <span id="adeoye2021sc"><span style="font-weight: 500">A. D. Adeoye and A. Bemporad</span>. (<span style="font-weight: 500">2021</span>). <span style="font-weight: 500">“SC-Reg: Training Overparameterized Neural Networks under Self-Concordant Regularization.”</span> IMT School for Advanced Studies Lucca.</span> <span class="links" style="text-transform: lowercase;"> <a href="https://arxiv.org/abs/2112.07344v1" class="fas fa-link" role="button" rel="external nofollow noopener" target="_blank">LINK</a> <a href="https://arxiv.org/pdf/2112.07344v1.pdf" class="fas fa-file-pdf" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a class="abstract fas fa-align-left" role="button">Abs</a> <a class="bibtex fas fa-quote-right" role="button">Bib</a> </span> <div class="abstract hidden"> <p>In this paper we propose the SC-Reg (self-concordant regularization) framework for learning overparameterized feedforward neural networks by incorporating second-order information in the Newton decrement framework for convex problems. We propose the generalized Gauss-Newton with Self-Concordant Regularization (SCoRe-GGN) algorithm that updates the network parameters each time it receives a new input batch. The proposed algorithm exploits the structure of the second-order information in the Hessian matrix, thereby reducing the training computational overhead. Although our current analysis considers only the convex case, numerical experiments show the efficiency of our method and its fast convergence under both convex and non-convex settings, which compare favorably against baseline first-order methods and a quasi-Newton method.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@techreport</span><span class="p">{</span><span class="nl">adeoye2021sc</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SC-Reg: Training Overparameterized Neural Networks under Self-Concordant Regularization}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Adeoye, Adeyemi D and Bemporad, Alberto}</span><span class="p">,</span>
  <span class="na">institution</span> <span class="p">=</span> <span class="s">{IMT School for Advanced Studies Lucca}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2112.07344}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> <script>document.addEventListener("DOMContentLoaded",function(){const e=document.querySelectorAll(".publications ol > li");if(console.log(`Total list items found: ${e.length}`),0===e.length)return void console.error("No list items found within '.publications ol > li'. Ensure that the bibliography tags generate <ol> and <li> elements.");const n=e.length;e.forEach((e,t)=>{const o=n-t;if(console.log(`Assigning number ${o} to list item at index ${t}`),e.querySelector(".reverse-number"))return void console.warn(`List item at index ${t} already has a reverse number. Skipping.`);const l=document.createElement("span");l.classList.add("reverse-number"),l.innerHTML="&bull;",l.style.fontSize="small",e.prepend(l)})});</script> </li> <li> <div class="row"> <div id="adeoye2021dnn" class="col"> <span id="adeoye2021dnn"><span style="font-weight: 500">A. D. Adeoye and P. Petersen</span>. (<span style="font-weight: 500">2021</span>). <span style="font-weight: 500">“A Deep Neural Network Optimization Method Via A Traffic Flow Model.”</span> African Institue for Mathematical Sciences, Rwanda.</span> <span class="links" style="text-transform: lowercase;"> <a href="https://zenodo.org/records/17385893" class="fas fa-link" role="button" rel="external nofollow noopener" target="_blank">LINK</a> <a href="/assets/pdf/adeoye-petersen-2021.pdf" class="fas fa-file-pdf" role="button">PDF</a> <a class="abstract fas fa-align-left" role="button">Abs</a> <a class="bibtex fas fa-quote-right" role="button">Bib</a> </span> <div class="abstract hidden"> <p>We present, via the solution of nonlinear parabolic partial differential equations (PDEs), a continuous-time formulation for stochastic optimization algorithms used for training deep neural networks. Using continuous-time formulation of stochastic differential equations (SDEs), relaxation approaches like the stochastic gradient descent (SGD) method are interpreted as the solution of nonlinear PDEs that arise from modeling physical problems. We reinterpret, through homogenization of SDEs, the modified SGD algorithm as the solution of the viscous Burgers’ equation that models a highway traffic flow.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@techreport</span><span class="p">{</span><span class="nl">adeoye2021dnn</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Deep Neural Network Optimization Method Via A Traffic Flow Model}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Adeoye, Adeyemi Damilare and Petersen, Philipp}</span><span class="p">,</span>
  <span class="na">institution</span> <span class="p">=</span> <span class="s">{African Institue for Mathematical Sciences, Rwanda}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.5281/zenodo.17385892}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> <script>document.addEventListener("DOMContentLoaded",function(){const e=document.querySelectorAll(".publications ol > li");if(console.log(`Total list items found: ${e.length}`),0===e.length)return void console.error("No list items found within '.publications ol > li'. Ensure that the bibliography tags generate <ol> and <li> elements.");const n=e.length;e.forEach((e,t)=>{const o=n-t;if(console.log(`Assigning number ${o} to list item at index ${t}`),e.querySelector(".reverse-number"))return void console.warn(`List item at index ${t} already has a reverse number. Skipping.`);const l=document.createElement("span");l.classList.add("reverse-number"),l.innerHTML="&bull;",l.style.fontSize="small",e.prepend(l)})});</script> </li> <li> <div class="row"> <div id="adeoye2018thesis" class="col"> <span id="adeoye2018thesis"><span style="font-weight: 500">A. D. Adeoye</span>. (<span style="font-weight: 500">2018</span>). <span style="font-weight: 500">“Blood Flow in an Inclined Tapered Stenosed Porous Artery under the Influence of Magnetic Field and Heat Transfer.”</span> African Institute for Mathematical Sciences, Cameroon.</span> <span class="links" style="text-transform: lowercase;"> <a href="https://library.nexteinstein.org/thesis/blood-flow-in-an-inclined-tapered-stenosed-porous-artery-under-the-influence-of-magnetic-field-and-heat-transfer/" class="fas fa-link" role="button" rel="external nofollow noopener" target="_blank">LINK</a> <a href="https://library.nexteinstein.org/wp-content/uploads/2023/01/Adeyemi-2017-2018.pdf" class="fas fa-file-pdf" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a class="abstract fas fa-align-left" role="button">Abs</a> <a class="bibtex fas fa-quote-right" role="button">Bib</a> </span> <div class="abstract hidden"> <p>A tapered inclined porous artery with stenosis was considered under the influence of magnetic field and heat transfer. The mathematical formulation for the momentum and energy equations of the blood flow considered to be Newtonian were obtained. The energy equation which was obtained by taking an extra factor of heat source and the nonlinear momentum equation were simplified under the assumption of mild stenosis. These equations were non-dimensionalized and solved using Differential Transform Method (DTM) to obtain expressions for velocity, temperature and volumetric flow rate. The graphs of the expressions were plotted against radius of the artery to simulate the effects of magnetic field, heat transfer and other fluid parameters on the velocity, temperature and the volumetric flow rate of the blood. It was observed that as the magnetic field parameter (M) increases, the velocity, temperature and the volumetric flow rate of the blood increase but wall shear stress decreases at the stenosis throat. It was further observed that the effects of heat transfer and magnetic field resulted into a greater variation in the volumetric flow of an inclined artery in the converging region than in the diverging region.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@mastersthesis</span><span class="p">{</span><span class="nl">adeoye2018thesis</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Blood Flow in an Inclined Tapered Stenosed Porous Artery under the Influence of Magnetic Field and Heat Transfer}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Adeoye, Adeyemi Damilare}</span><span class="p">,</span>
  <span class="na">institution</span> <span class="p">=</span> <span class="s">{African Institute for Mathematical Sciences, Cameroon}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.5281/zenodo.17386590}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> <script>document.addEventListener("DOMContentLoaded",function(){const e=document.querySelectorAll(".publications ol > li");if(console.log(`Total list items found: ${e.length}`),0===e.length)return void console.error("No list items found within '.publications ol > li'. Ensure that the bibliography tags generate <ol> and <li> elements.");const n=e.length;e.forEach((e,t)=>{const o=n-t;if(console.log(`Assigning number ${o} to list item at index ${t}`),e.querySelector(".reverse-number"))return void console.warn(`List item at index ${t} already has a reverse number. Skipping.`);const l=document.createElement("span");l.classList.add("reverse-number"),l.innerHTML="&bull;",l.style.fontSize="small",e.prepend(l)})});</script> </li> <li> <div class="row"> <div id="adeoye2016thesis" class="col"> <span id="adeoye2016thesis"><span style="font-weight: 500">A. D. Adeoye</span>. (<span style="font-weight: 500">2016</span>). <span style="font-weight: 500">“ON SOME FINITE DIFFERENCE METHODS FOR SOLVING PARTIAL DIFFERENTIAL EQUATIONS.”</span> University of Ilorin, Ilorin, Nigeria.</span> <span class="links" style="text-transform: lowercase;"> </span> </div> </div> <script>document.addEventListener("DOMContentLoaded",function(){const e=document.querySelectorAll(".publications ol > li");if(console.log(`Total list items found: ${e.length}`),0===e.length)return void console.error("No list items found within '.publications ol > li'. Ensure that the bibliography tags generate <ol> and <li> elements.");const n=e.length;e.forEach((e,t)=>{const o=n-t;if(console.log(`Assigning number ${o} to list item at index ${t}`),e.querySelector(".reverse-number"))return void console.warn(`List item at index ${t} already has a reverse number. Skipping.`);const l=document.createElement("span");l.classList.add("reverse-number"),l.innerHTML="&bull;",l.style.fontSize="small",e.prepend(l)})});</script> </li> </ol> </div> </div> </article> </div> </main> </div> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-W557485GR3"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-W557485GR3");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>